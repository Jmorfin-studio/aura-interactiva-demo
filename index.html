<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Aura Interactiva - Demo Final</title>
    <style>
        /* ... (CSS sin cambios) ... */
    </style>
</head>
<body>
    <!-- ... (HTML sin cambios) ... -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ... (constantes sin cambios) ...
            
            // --- INICIO DE LA LÓGICA DE RECONOCIMIENTO DE VOZ ---
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert("Tu navegador no soporta el reconocimiento de voz. Por favor, usa Chrome.");
                return;
            }
            const recognition = new SpeechRecognition();
            recognition.lang = 'es-MX';
            recognition.interimResults = false;
            recognition.continuous = false;
            // --- FIN DE LA LÓGICA DE RECONOCIMIENTO DE VOZ ---
            
            let socket, isConversationActive = false;
            let iframeReady = false;
            const HEYGEN_IFRAME_URL = '...'; // URL sin cambios

            function sanitizeText(text) { /* ... (función sin cambios) ... */ }

            function connectWebSocket() {
                // ... (código de conexión sin cambios) ...
                socket.onopen = () => {
                    statusDiv.textContent = "Conectado. ¡Habla ahora!";
                    // Ya no necesitamos MediaRecorder
                };
                // ... (código de onmessage sin cambios) ...
            }

            micButton.addEventListener('click', () => {
                if (isConversationActive) {
                    recognition.stop();
                    micButton.classList.remove('active');
                    isConversationActive = false;
                } else {
                    if (!socket || socket.readyState !== WebSocket.OPEN) {
                        connectWebSocket();
                    }
                    recognition.start();
                    micButton.classList.add('active');
                    statusDiv.textContent = "Escuchando...";
                    isConversationActive = true;
                }
            });

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                statusDiv.textContent = `Tú dijiste: "${transcript}"`;
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.send(transcript); // Enviamos el texto directamente
                }
            };

            recognition.onerror = (event) => {
                console.error("Error en reconocimiento de voz:", event.error);
                statusDiv.textContent = "Error al escuchar. Intenta de nuevo.";
                micButton.classList.remove('active');
                isConversationActive = false;
            };

            recognition.onend = () => {
                if (isConversationActive) { // Si la conversación debe continuar, vuelve a escuchar
                    micButton.classList.remove('active');
                    statusDiv.textContent = "Tu turno de hablar...";
                    isConversationActive = false;
                }
            };
        });
    </script>
</body>
</html>